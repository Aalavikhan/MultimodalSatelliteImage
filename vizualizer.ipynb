{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75b944c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ timm library loaded successfully!\n",
      "‚úÖ Libraries loaded successfully!\n",
      "üî• PyTorch version: 2.9.0+cu126\n",
      "üéÆ CUDA available: True\n",
      "üì¶ timm version: 1.0.21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Swin Transformer + Tabular Multimodal Energy Prediction\n",
    "FIXED VERSION - Corrected Phase 1 Training Strategy\n",
    "NO DATA LEAKAGE VERSION - Clean features only\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandomRotation, RandomHorizontalFlip\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "import cv2\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import timm\n",
    "    print(\"‚úÖ timm library loaded successfully!\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå timm not found. Please install: pip install timm\")\n",
    "    raise\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully!\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"üì¶ timm version: {timm.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f061c5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tabular encoder ready - NO LEAKAGE!\n",
      "   Features: population, area, density, seasonality, time trend\n"
     ]
    }
   ],
   "source": [
    "class TabularEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Clean tabular encoder - NO DATA LEAKAGE\n",
    "    Features (6 total):\n",
    "    - log_population, log_area, log_density\n",
    "    - month_sin, month_cos, year_normalized\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features=6, output_dim=512, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Tabular encoder ready - NO LEAKAGE!\")\n",
    "print(\"   Features: population, area, density, seasonality, time trend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a48c5b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fusion layer ready!\n"
     ]
    }
   ],
   "source": [
    "class FusionLayer(nn.Module):\n",
    "    \"\"\"Simple concatenation + MLP fusion\"\"\"\n",
    "    def __init__(self, vision_dim=512, tabular_dim=512, output_dim=512, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(vision_dim + tabular_dim, 1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(1024, output_dim),\n",
    "            nn.LayerNorm(output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, vision_feat, tabular_feat):\n",
    "        combined = torch.cat([vision_feat, tabular_feat], dim=-1)\n",
    "        return self.fusion(combined)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fusion layer ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eb8e205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Swin Multimodal Model assembled!\n",
      "\n",
      "üìä Architecture Summary:\n",
      "   1. Swin Transformer (pretrained) - ~28M params\n",
      "   2. Vision Projection - ~0.5M params\n",
      "   3. Tabular Encoder (6 features) - ~0.3M params\n",
      "   4. Fusion Layer - ~1M params\n",
      "   5. Prediction Head - ~0.5M params\n",
      "   ‚ú® TOTAL: ~30M parameters\n"
     ]
    }
   ],
   "source": [
    "class SwinMultimodalModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Swin + Tabular Multimodal Model\n",
    "    Architecture:\n",
    "    1. Swin Transformer (pretrained) ‚Üí 768-dim\n",
    "    2. Vision Projection ‚Üí 512-dim\n",
    "    3. Tabular Encoder ‚Üí 512-dim\n",
    "    4. Fusion (concat + MLP) ‚Üí 512-dim\n",
    "    5. Prediction Head ‚Üí 1\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 swin_variant='swin_tiny_patch4_window7_224',\n",
    "                 num_tabular_features=6,\n",
    "                 dropout=0.3,\n",
    "                 pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        print(f\"\\nüî® Building Swin Multimodal Model...\")\n",
    "        print(f\"   Vision: {swin_variant}\")\n",
    "        print(f\"   Tabular features: {num_tabular_features}\")\n",
    "        print(f\"   Pretrained: {pretrained}\")\n",
    "\n",
    "        # 1. Swin Transformer\n",
    "        self.swin = timm.create_model(\n",
    "            swin_variant,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "            global_pool='avg',\n",
    "            in_chans=1,\n",
    "            img_size=64\n",
    "        )\n",
    "\n",
    "        swin_out_dim = self.swin.num_features\n",
    "        print(f\"   Swin output dim: {swin_out_dim}\")\n",
    "\n",
    "        # 2. Vision projection\n",
    "        self.vision_proj = nn.Sequential(\n",
    "            nn.Linear(swin_out_dim, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        # 3. Tabular encoder\n",
    "        self.tabular_encoder = TabularEncoder(\n",
    "            num_features=num_tabular_features,\n",
    "            output_dim=512,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 4. Fusion layer\n",
    "        self.fusion = FusionLayer(\n",
    "            vision_dim=512,\n",
    "            tabular_dim=512,\n",
    "            output_dim=512,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 5. Prediction head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "        print(f\"   ‚úÖ Multimodal model built!\")\n",
    "\n",
    "    def freeze_backbone(self):\n",
    "        \"\"\"Freeze ONLY Swin backbone\"\"\"\n",
    "        for p in self.swin.parameters():\n",
    "            p.requires_grad = False\n",
    "        print(\"   üîí Swin backbone frozen\")\n",
    "\n",
    "    def unfreeze_all(self):\n",
    "        \"\"\"Unfreeze everything\"\"\"\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = True\n",
    "        print(\"   üîì All parameters unfrozen\")\n",
    "\n",
    "    def forward(self, img, tabular):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img: (B, 1, 64, 64) - nightlight images\n",
    "            tabular: (B, 6) - clean features\n",
    "        Returns:\n",
    "            predictions: (B, 1)\n",
    "        \"\"\"\n",
    "        vision_feat = self.swin(img)\n",
    "        vision_feat = self.vision_proj(vision_feat)\n",
    "        tabular_feat = self.tabular_encoder(tabular)\n",
    "        fused = self.fusion(vision_feat, tabular_feat)\n",
    "        output = self.head(fused)\n",
    "        return output\n",
    "\n",
    "\n",
    "print(\"\\n‚úÖ Swin Multimodal Model assembled!\")\n",
    "print(\"\\nüìä Architecture Summary:\")\n",
    "print(\"   1. Swin Transformer (pretrained) - ~28M params\")\n",
    "print(\"   2. Vision Projection - ~0.5M params\")\n",
    "print(\"   3. Tabular Encoder (6 features) - ~0.3M params\")\n",
    "print(\"   4. Fusion Layer - ~1M params\")\n",
    "print(\"   5. Prediction Head - ~0.5M params\")\n",
    "print(\"   ‚ú® TOTAL: ~30M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4841427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from torch.utils.data import DataLoader\n",
    "# from sklearn.metrics import r2_score, mean_absolute_error\n",
    "# from scipy.stats import pearsonr\n",
    "# import os\n",
    "\n",
    "\n",
    "# # ==========================================\n",
    "# # 0. FIX THE LOADING ERROR\n",
    "# # ==========================================\n",
    "# # This tells PyTorch to trust the Numpy scalars saved in your checkpoint\n",
    "# import torch.serialization\n",
    "# try:\n",
    "#     # Option A: Add to safe globals (Preferred for PyTorch 2.6+)\n",
    "#     torch.serialization.add_safe_globals([np._core.multiarray.scalar])\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# # ==========================================\n",
    "# # 1. DEFINE ARCHITECTURE (Required for Loading)\n",
    "# # ==========================================\n",
    "# # Note: Ensure TabularEncoder, FusionLayer, and SwinMultimodalModel \n",
    "# # classes are copied here from your original notebook.\n",
    "\n",
    "# # ==========================================\n",
    "# # 2. LOAD PRE-TRAINED MODEL & SCALERS\n",
    "# # ==========================================\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# checkpoint_path = 'best_multimodal_model_fixed.pt'\n",
    "\n",
    "# print(f\"üîÑ Loading checkpoint: {checkpoint_path}\")\n",
    "# checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# # Reconstruct Model\n",
    "# model = SwinMultimodalModel(num_tabular_features=6, pretrained=False)\n",
    "# model.load_state_dict(checkpoint['model'])\n",
    "# model.to(device).eval()\n",
    "\n",
    "# # Retrieve Scalers\n",
    "# feat_scaler = checkpoint['feat_scaler']\n",
    "# targ_scaler = checkpoint['targ_scaler']\n",
    "\n",
    "# # ==========================================\n",
    "# # 3. GET PREDICTIONS (Single Pass)\n",
    "# # ==========================================\n",
    "# all_preds, all_targets = [], []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for imgs, feats, labels in test_loader: # Use your existing test_loader\n",
    "#         outputs = model(imgs.to(device), feats.to(device))\n",
    "#         all_preds.append(outputs.cpu().numpy())\n",
    "#         all_targets.append(labels.cpu().numpy())\n",
    "\n",
    "# # Inverse Transform to original kWh\n",
    "# preds_log = targ_scaler.inverse_transform(np.concatenate(all_preds).reshape(-1, 1)).ravel()\n",
    "# targets_log = targ_scaler.inverse_transform(np.concatenate(all_targets).reshape(-1, 1)).ravel()\n",
    "\n",
    "# preds_orig = np.expm1(preds_log)\n",
    "# targets_orig = np.expm1(targets_log)\n",
    "\n",
    "# # ==========================================\n",
    "# # 4. GENERATE THESIS GRAPHS\n",
    "# # ==========================================\n",
    "# plt.figure(figsize=(20, 10))\n",
    "\n",
    "# # GRAPH 1: Predicted vs Actual Scatter\n",
    "# plt.subplot(1, 2, 1)\n",
    "# sns.regplot(x=targets_orig, y=preds_orig, scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
    "# plt.plot([targets_orig.min(), targets_orig.max()], [targets_orig.min(), targets_orig.max()], 'k--', lw=2)\n",
    "# plt.title(f\"Predicted vs Actual Energy Use\\n(Pearson R: {pearsonr(targets_orig, preds_orig)[0]:.4f})\")\n",
    "# plt.xlabel(\"Actual kWh\")\n",
    "# plt.ylabel(\"Predicted kWh\")\n",
    "\n",
    "# # GRAPH 2: Residual Analysis\n",
    "# plt.subplot(1, 2, 2)\n",
    "# residuals = targets_orig - preds_orig\n",
    "# sns.histplot(residuals, kde=True, color=\"purple\")\n",
    "# plt.axvline(0, color='red', linestyle='--')\n",
    "# plt.title(\"Distribution of Residuals (Errors)\")\n",
    "# plt.xlabel(\"Error (Actual - Predicted)\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # GRAPH 3: Accuracy Tiers (Thesis Bar Chart)\n",
    "# errors = np.abs((targets_orig - preds_orig) / (targets_orig + 1e-8)) * 100\n",
    "# acc_5 = np.mean(errors <= 5) * 100\n",
    "# acc_10 = np.mean(errors <= 10) * 100\n",
    "# acc_20 = np.mean(errors <= 20) * 100\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# bars = plt.bar(['Within ¬±5%', 'Within ¬±10%', 'Within ¬±20%'], [acc_5, acc_10, acc_20], color=['#4CAF50', '#2196F3', '#FF9800'])\n",
    "# plt.ylabel(\"Percentage of Test Samples (%)\")\n",
    "# plt.title(\"Model Prediction Accuracy Thresholds\")\n",
    "# for bar in bars:\n",
    "#     yval = bar.get_height()\n",
    "#     plt.text(bar.get_x() + bar.get_width()/2, yval + 1, f'{yval:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "# plt.ylim(0, 110)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2ac734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from sklearn.metrics import r2_score, mean_absolute_error\n",
    "# from scipy.stats import pearsonr\n",
    "# import timm\n",
    "# import os\n",
    "\n",
    "# # ==========================================\n",
    "# # 0. FIX THE LOADING ERROR\n",
    "# # ==========================================\n",
    "# # This tells PyTorch to trust the Numpy scalars saved in your checkpoint\n",
    "# import torch.serialization\n",
    "# try:\n",
    "#     # Option A: Add to safe globals (Preferred for PyTorch 2.6+)\n",
    "#     torch.serialization.add_safe_globals([np._core.multiarray.scalar])\n",
    "# except:\n",
    "#     pass \n",
    "\n",
    "# # # ==========================================\n",
    "# # # 1. DEFINE ARCHITECTURE (Must match original)\n",
    "# # # ==========================================\n",
    "# # class TabularEncoder(nn.Module):\n",
    "# #     def __init__(self, input_dim, output_dim=128):\n",
    "# #         super().__init__()\n",
    "# #         self.net = nn.Sequential(\n",
    "# #             nn.Linear(input_dim, 256),\n",
    "# #             nn.ReLU(),\n",
    "# #             nn.BatchNorm1d(256),\n",
    "# #             nn.Dropout(0.2),\n",
    "# #             nn.Linear(256, output_dim),\n",
    "# #             nn.ReLU()\n",
    "# #         )\n",
    "# #     def forward(self, x): return self.net(x)\n",
    "\n",
    "# # class FusionLayer(nn.Module):\n",
    "# #     def __init__(self, vision_dim, tab_dim, output_dim=256):\n",
    "# #         super().__init__()\n",
    "# #         self.fusion = nn.Sequential(\n",
    "# #             nn.Linear(vision_dim + tab_dim, 512),\n",
    "# #             nn.ReLU(),\n",
    "# #             nn.Dropout(0.3),\n",
    "# #             nn.Linear(512, output_dim),\n",
    "# #             nn.ReLU(),\n",
    "# #             nn.Linear(output_dim, 1)\n",
    "# #         )\n",
    "# #     def forward(self, v, t): return self.fusion(torch.cat([v, t], dim=1))\n",
    "\n",
    "# # class SwinMultimodalModel(nn.Module):\n",
    "# #     def __init__(self, swin_variant='swin_tiny_patch4_window7_224', num_tabular_features=6):\n",
    "# #         super().__init__()\n",
    "# #         self.swin = timm.create_model(swin_variant, pretrained=False, num_classes=0)\n",
    "# #         self.vision_proj = nn.Linear(self.swin.num_features, 256)\n",
    "# #         self.tab_encoder = TabularEncoder(num_tabular_features, 128)\n",
    "# #         self.fusion = FusionLayer(256, 128)\n",
    "\n",
    "# #     def forward(self, img, tab):\n",
    "# #         v_feat = self.swin(img)\n",
    "# #         v_feat = self.vision_proj(v_feat)\n",
    "# #         t_feat = self.tab_encoder(tab)\n",
    "# #         return self.fusion(v_feat, t_feat)\n",
    "\n",
    "# # ==========================================\n",
    "# # 2. LOAD DATA & MODEL\n",
    "# # ==========================================\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# checkpoint_path = 'best_multimodal_model_fixed.pt'\n",
    "\n",
    "# print(f\"üîÑ Loading checkpoint: {checkpoint_path}...\")\n",
    "# # FIX: Use weights_only=False to allow the Numpy Scalers to load\n",
    "# checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "\n",
    "# # Reconstruct Model\n",
    "# model = SwinMultimodalModel(num_tabular_features=6)\n",
    "# model.load_state_dict(checkpoint['model'])\n",
    "# model.to(device).eval()\n",
    "\n",
    "# # Retrieve Scalers\n",
    "# targ_scaler = checkpoint['targ_scaler']\n",
    "# print(\"‚úÖ Model and Scalers loaded successfully!\")\n",
    "\n",
    "# # ==========================================\n",
    "# # 3. GENERATE ANALYTICS & GRAPHS\n",
    "# # ==========================================\n",
    "# # (Assuming you have test_loader ready from your previous setup)\n",
    "\n",
    "# def generate_thesis_visuals(test_loader):\n",
    "#     all_preds, all_targets = [], []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for imgs, feats, labels in test_loader:\n",
    "#             outputs = model(imgs.to(device), feats.to(device))\n",
    "#             all_preds.append(outputs.cpu().numpy())\n",
    "#             all_targets.append(labels.cpu().numpy())\n",
    "\n",
    "#     # Inverse Transform\n",
    "#     preds_log = targ_scaler.inverse_transform(np.concatenate(all_preds).reshape(-1, 1)).ravel()\n",
    "#     targets_log = targ_scaler.inverse_transform(np.concatenate(all_targets).reshape(-1, 1)).ravel()\n",
    "    \n",
    "#     # Convert from Log space back to real kWh\n",
    "#     preds_orig = np.expm1(preds_log)\n",
    "#     targets_orig = np.expm1(targets_log)\n",
    "\n",
    "#     # --- PLOT 1: Regression Performance ---\n",
    "#     plt.figure(figsize=(15, 6))\n",
    "    \n",
    "#     plt.subplot(1, 2, 1)\n",
    "    \n",
    "#     sns.regplot(x=targets_orig, y=preds_orig, scatter_kws={'alpha':0.3, 'color':'blue'}, line_kws={'color':'red'})\n",
    "#     plt.plot([targets_orig.min(), targets_orig.max()], [targets_orig.min(), targets_orig.max()], 'k--', alpha=0.7)\n",
    "#     plt.title(f\"Predicted vs Actual Energy Consumption\\n(R¬≤: {r2_score(targets_orig, preds_orig):.4f})\")\n",
    "#     plt.xlabel(\"Actual Consumption (kWh)\")\n",
    "#     plt.ylabel(\"Model Prediction (kWh)\")\n",
    "\n",
    "#     # --- PLOT 2: Residual (Error) Distribution ---\n",
    "#     plt.subplot(1, 2, 2)\n",
    "    \n",
    "#     residuals = targets_orig - preds_orig\n",
    "#     sns.histplot(residuals, kde=True, color=\"forestgreen\")\n",
    "#     plt.axvline(0, color='red', linestyle='--')\n",
    "#     plt.title(\"Error Distribution (Residuals)\")\n",
    "#     plt.xlabel(\"Prediction Error (kWh)\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     # --- PLOT 3: Error Thresholds ---\n",
    "#     errors = np.abs((targets_orig - preds_orig) / (targets_orig + 1e-8)) * 100\n",
    "#     acc_10 = np.mean(errors <= 10) * 100\n",
    "#     acc_20 = np.mean(errors <= 20) * 100\n",
    "    \n",
    "#     plt.figure(figsize=(8, 5))\n",
    "    \n",
    "#     sns.barplot(x=['Within 10% Error', 'Within 20% Error'], y=[acc_10, acc_20], palette='viridis')\n",
    "#     plt.ylabel(\"Percentage of Samples (%)\")\n",
    "#     plt.title(\"Model Reliability (Accuracy Tiers)\")\n",
    "#     plt.show()\n",
    "\n",
    "# # Run it\n",
    "# generate_thesis_visuals(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fae3f33",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SwinMultimodalModel:\n\tMissing key(s) in state_dict: \"vision_proj.weight\", \"vision_proj.bias\", \"tab_encoder.net.0.weight\", \"tab_encoder.net.0.bias\", \"tab_encoder.net.2.weight\", \"tab_encoder.net.2.bias\", \"tab_encoder.net.2.running_mean\", \"tab_encoder.net.2.running_var\", \"tab_encoder.net.4.weight\", \"tab_encoder.net.4.bias\", \"fusion.fusion.3.weight\", \"fusion.fusion.3.bias\". \n\tUnexpected key(s) in state_dict: \"tabular_encoder.encoder.0.weight\", \"tabular_encoder.encoder.0.bias\", \"tabular_encoder.encoder.3.weight\", \"tabular_encoder.encoder.3.bias\", \"tabular_encoder.encoder.6.weight\", \"tabular_encoder.encoder.6.bias\", \"head.0.weight\", \"head.0.bias\", \"head.1.weight\", \"head.1.bias\", \"head.4.weight\", \"head.4.bias\", \"head.5.weight\", \"head.5.bias\", \"head.8.weight\", \"head.8.bias\", \"vision_proj.0.weight\", \"vision_proj.0.bias\", \"vision_proj.1.weight\", \"vision_proj.1.bias\", \"fusion.fusion.1.weight\", \"fusion.fusion.1.bias\", \"fusion.fusion.4.weight\", \"fusion.fusion.4.bias\". \n\tsize mismatch for swin.patch_embed.proj.weight: copying a param with shape torch.Size([96, 1, 4, 4]) from checkpoint, the shape in current model is torch.Size([96, 3, 4, 4]).\n\tsize mismatch for swin.layers.2.blocks.0.attn.relative_position_bias_table: copying a param with shape torch.Size([49, 12]) from checkpoint, the shape in current model is torch.Size([169, 12]).\n\tsize mismatch for swin.layers.2.blocks.1.attn.relative_position_bias_table: copying a param with shape torch.Size([49, 12]) from checkpoint, the shape in current model is torch.Size([169, 12]).\n\tsize mismatch for swin.layers.2.blocks.2.attn.relative_position_bias_table: copying a param with shape torch.Size([49, 12]) from checkpoint, the shape in current model is torch.Size([169, 12]).\n\tsize mismatch for swin.layers.2.blocks.3.attn.relative_position_bias_table: copying a param with shape torch.Size([49, 12]) from checkpoint, the shape in current model is torch.Size([169, 12]).\n\tsize mismatch for swin.layers.2.blocks.4.attn.relative_position_bias_table: copying a param with shape torch.Size([49, 12]) from checkpoint, the shape in current model is torch.Size([169, 12]).\n\tsize mismatch for swin.layers.2.blocks.5.attn.relative_position_bias_table: copying a param with shape torch.Size([49, 12]) from checkpoint, the shape in current model is torch.Size([169, 12]).\n\tsize mismatch for swin.layers.3.blocks.0.attn.relative_position_bias_table: copying a param with shape torch.Size([9, 24]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n\tsize mismatch for swin.layers.3.blocks.1.attn.relative_position_bias_table: copying a param with shape torch.Size([9, 24]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n\tsize mismatch for fusion.fusion.0.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([512, 384]).\n\tsize mismatch for fusion.fusion.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for fusion.fusion.5.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1, 256]).\n\tsize mismatch for fusion.fusion.5.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 147\u001b[39m\n\u001b[32m    145\u001b[39m checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    146\u001b[39m model = SwinMultimodalModel(num_tabular_features=\u001b[32m6\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m model.to(device).eval()\n\u001b[32m    150\u001b[39m feat_scaler = checkpoint[\u001b[33m'\u001b[39m\u001b[33mfeat_scaler\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FA004\\Desktop\\satimg2\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2629\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2621\u001b[39m         error_msgs.insert(\n\u001b[32m   2622\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2623\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2624\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2625\u001b[39m             ),\n\u001b[32m   2626\u001b[39m         )\n\u001b[32m   2628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2629\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2630\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2631\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2632\u001b[39m         )\n\u001b[32m   2633\u001b[39m     )\n\u001b[32m   2634\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for SwinMultimodalModel:\n\tMissing key(s) in state_dict: \"vision_proj.weight\", \"vision_proj.bias\", \"tab_encoder.net.0.weight\", \"tab_encoder.net.0.bias\", \"tab_encoder.net.2.weight\", \"tab_encoder.net.2.bias\", \"tab_encoder.net.2.running_mean\", \"tab_encoder.net.2.running_var\", \"tab_encoder.net.4.weight\", \"tab_encoder.net.4.bias\", \"fusion.fusion.3.weight\", \"fusion.fusion.3.bias\". \n\tUnexpected key(s) in state_dict: \"tabular_encoder.encoder.0.weight\", \"tabular_encoder.encoder.0.bias\", \"tabular_encoder.encoder.3.weight\", \"tabular_encoder.encoder.3.bias\", \"tabular_encoder.encoder.6.weight\", \"tabular_encoder.encoder.6.bias\", \"head.0.weight\", \"head.0.bias\", \"head.1.weight\", \"head.1.bias\", \"head.4.weight\", \"head.4.bias\", \"head.5.weight\", \"head.5.bias\", \"head.8.weight\", \"head.8.bias\", \"vision_proj.0.weight\", \"vision_proj.0.bias\", \"vision_proj.1.weight\", \"vision_proj.1.bias\", \"fusion.fusion.1.weight\", \"fusion.fusion.1.bias\", \"fusion.fusion.4.weight\", \"fusion.fusion.4.bias\". \n\tsize mismatch for swin.patch_embed.proj.weight: copying a param with shape torch.Size([96, 1, 4, 4]) from checkpoint, the shape in current model is torch.Size([96, 3, 4, 4]).\n\tsize mismatch for swin.layers.2.blocks.0.attn.relative_position_bias_table: copying a param with shape torch.Size([49, 12]) from checkpoint, the shape in current model is torch.Size([169, 12]).\n\tsize mismatch for swin.layers.2.blocks.1.attn.relative_position_bias_table: copying a param with shape torch.Size([49, 12]) from checkpoint, the shape in current model is torch.Size([169, 12]).\n\tsize mismatch for swin.layers.2.blocks.2.attn.relative_position_bias_table: copying a param with shape torch.Size([49, 12]) from checkpoint, the shape in current model is torch.Size([169, 12]).\n\tsize mismatch for swin.layers.2.blocks.3.attn.relative_position_bias_table: copying a param with shape torch.Size([49, 12]) from checkpoint, the shape in current model is torch.Size([169, 12]).\n\tsize mismatch for swin.layers.2.blocks.4.attn.relative_position_bias_table: copying a param with shape torch.Size([49, 12]) from checkpoint, the shape in current model is torch.Size([169, 12]).\n\tsize mismatch for swin.layers.2.blocks.5.attn.relative_position_bias_table: copying a param with shape torch.Size([49, 12]) from checkpoint, the shape in current model is torch.Size([169, 12]).\n\tsize mismatch for swin.layers.3.blocks.0.attn.relative_position_bias_table: copying a param with shape torch.Size([9, 24]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n\tsize mismatch for swin.layers.3.blocks.1.attn.relative_position_bias_table: copying a param with shape torch.Size([9, 24]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n\tsize mismatch for fusion.fusion.0.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([512, 384]).\n\tsize mismatch for fusion.fusion.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for fusion.fusion.5.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1, 256]).\n\tsize mismatch for fusion.fusion.5.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "import timm\n",
    "import os\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "\n",
    "# ==========================================\n",
    "# 0. PYTORCH 2.6+ COMPATIBILITY FIX\n",
    "# ==========================================\n",
    "import torch.serialization\n",
    "try:\n",
    "    torch.serialization.add_safe_globals([np._core.multiarray.scalar])\n",
    "except:\n",
    "    pass \n",
    "\n",
    "# ==========================================\n",
    "# 1. IDENTICAL ARCHITECTURE (From your Notebook)\n",
    "# ==========================================\n",
    "class TabularEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class FusionLayer(nn.Module):\n",
    "    def __init__(self, vision_dim, tab_dim, output_dim=256):\n",
    "        super().__init__()\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(vision_dim + tab_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_dim, 1)\n",
    "        )\n",
    "    def forward(self, v, t): return self.fusion(torch.cat([v, t], dim=1))\n",
    "\n",
    "class SwinMultimodalModel(nn.Module):\n",
    "    def __init__(self, swin_variant='swin_tiny_patch4_window7_224', num_tabular_features=6, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.swin = timm.create_model(swin_variant, pretrained=pretrained, num_classes=0)\n",
    "        self.vision_proj = nn.Linear(self.swin.num_features, 256)\n",
    "        self.tab_encoder = TabularEncoder(num_tabular_features, 128)\n",
    "        self.fusion = FusionLayer(256, 128)\n",
    "\n",
    "    def forward(self, img, tab):\n",
    "        v_feat = self.swin(img)\n",
    "        v_feat = self.vision_proj(v_feat)\n",
    "        t_feat = self.tab_encoder(tab)\n",
    "        return self.fusion(v_feat, t_feat)\n",
    "\n",
    "# ==========================================\n",
    "# 2. IDENTICAL DATASET CLASS\n",
    "# ==========================================\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, image_paths, features, targets, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None: # Fallback if path is wrong\n",
    "            image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.features[idx], self.targets[idx]\n",
    "\n",
    "# ==========================================\n",
    "# 3. IDENTICAL DATA PREPARATION (Matching your Notebook)\n",
    "# ==========================================\n",
    "def get_test_loader_identical(csv_path, image_dir, feat_scaler, targ_scaler):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 1. Filtering logic exactly as per notebook\n",
    "    df = df[(df['Energy Use per Capita (kWh)'] > 0) & (df['Population'] > 0) & (df['Area (Sq. Km)'] > 0)]\n",
    "    \n",
    "    # 2. Feature engineering exactly as per notebook\n",
    "    df['log_population'] = np.log1p(df['Population'])\n",
    "    df['log_area'] = np.log1p(df['Area (Sq. Km)'])\n",
    "    df['log_density'] = np.log1p(df['Population'] / df['Area (Sq. Km)'])\n",
    "    df['date'] = pd.to_datetime(df['Date (month/year)'])\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['date'].dt.month / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['date'].dt.month / 12)\n",
    "    df['year_normalized'] = (df['date'].dt.year - 2012) / (2024 - 2012)\n",
    "\n",
    "    # 3. Time Series Split: Test = Year > 2022\n",
    "    test_df = df[df['date'].dt.year > 2022].copy()\n",
    "    \n",
    "    features_cols = ['log_population', 'log_area', 'log_density', 'month_sin', 'month_cos', 'year_normalized']\n",
    "    \n",
    "    # 4. Use provided scalers (don't fit_transform, only transform)\n",
    "    X_tab = feat_scaler.transform(test_df[features_cols])\n",
    "    y_log = np.log1p(test_df[['Energy Use per Capita (kWh)']])\n",
    "    y_scaled = targ_scaler.transform(y_log)\n",
    "\n",
    "    image_paths = []\n",
    "    for _, row in test_df.iterrows():\n",
    "        # Matching your path logic: IMAGE_DIR / Country / Country_Year_Month.png\n",
    "        filename = f\"{row['Country']}_{row['date'].year}_{row['date'].month:02d}.png\"\n",
    "        image_paths.append(os.path.join(image_dir, row['Country'], filename))\n",
    "\n",
    "    # Identical Transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    ds = MultimodalDataset(image_paths, X_tab, y_scaled, transform=transform)\n",
    "    return DataLoader(ds, batch_size=32, shuffle=False), test_df\n",
    "\n",
    "# ==========================================\n",
    "# 4. LOADING AND VISUALIZATION\n",
    "# ==========================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint_path = 'best_multimodal_model_fixed.pt'\n",
    "CSV_PATH = 'C:/Users/FA004/Desktop/satimg2/data.csv'\n",
    "IMAGE_DIR = r'C:\\Users\\FA004\\Desktop\\satimg2.1\\images_png_view'\n",
    "\n",
    "# Load\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "model = SwinMultimodalModel(num_tabular_features=6)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.to(device).eval()\n",
    "\n",
    "feat_scaler = checkpoint['feat_scaler']\n",
    "targ_scaler = checkpoint['targ_scaler']\n",
    "\n",
    "test_loader, test_df_cleaned = get_test_loader_identical(CSV_PATH, IMAGE_DIR, feat_scaler, targ_scaler)\n",
    "\n",
    "def generate_thesis_plots(loader):\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, feats, labels in loader:\n",
    "            outputs = model(imgs.to(device), feats.to(device))\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_targets.append(labels.cpu().numpy())\n",
    "\n",
    "    # De-scale to log space, then de-log to original space\n",
    "    p_log = targ_scaler.inverse_transform(np.concatenate(all_preds).reshape(-1, 1))\n",
    "    t_log = targ_scaler.inverse_transform(np.concatenate(all_targets).reshape(-1, 1))\n",
    "    \n",
    "    p_orig = np.expm1(p_log).ravel()\n",
    "    t_orig = np.expm1(t_log).ravel()\n",
    "\n",
    "    # --- PLOT 1: RegPlot (Standard Thesis Visual) ---\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.regplot(x=t_orig, y=p_orig, scatter_kws={'alpha':0.4}, line_kws={'color':'red'})\n",
    "    plt.plot([t_orig.min(), t_orig.max()], [t_orig.min(), t_orig.max()], 'k--', alpha=0.8)\n",
    "    plt.title(f\"Model Performance: Predicted vs Actual\\n(R¬≤: {r2_score(t_orig, p_orig):.4f})\")\n",
    "    plt.xlabel(\"Actual Energy Use (kWh)\")\n",
    "    plt.ylabel(\"Predicted Energy Use (kWh)\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- PLOT 2: Residual Histogram ---\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(t_orig - p_orig, kde=True, color=\"blue\")\n",
    "    plt.axvline(0, color='red', ls='--')\n",
    "    plt.title(\"Error Distribution (Residuals)\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- PLOT 3: Error Metrics by Year ---\n",
    "    # Add metrics to df for grouped analysis\n",
    "    test_df_cleaned['Absolute_Error_Pct'] = np.abs((t_orig - p_orig) / (t_orig + 1e-8)) * 100\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    sns.barplot(x=test_df_cleaned['date'].dt.year, y=test_df_cleaned['Absolute_Error_Pct'])\n",
    "    plt.title(\"Average MAPE % by Year (Test Set)\")\n",
    "    plt.show()\n",
    "\n",
    "generate_thesis_plots(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
